import { GoogleGenerativeAI, Content } from "@google/generative-ai";
import { executeAiTool, ToolContext } from "./toolHandler";
import { createClient } from "@supabase/supabase-js";
import { mapOpenAIToolsToGemini } from "./geminiMapper";

// Importa√ß√£o est√°tica do JSON ‚Äî webpack resolve em build time (sem fs em runtime)
import openaiTools from "./tools.json";
const GEMINI_TOOLS = mapOpenAIToolsToGemini(openaiTools as any[]);

type OrchestratorParams = {
    restaurantId: string;
    chatId: string;
    waChatId: string;
    instanceName?: string;
    incomingText: string;
};

// ‚îÄ‚îÄ‚îÄ SUPABASE ADMIN CLIENT (Service Role ‚Äî sem cookies) ‚îÄ‚îÄ‚îÄ
// O orquestrador roda em background (fire-and-forget), ent√£o N√ÉO pode
// depender de cookies de sess√£o. Usamos a service_role key.
function getSupabaseAdmin() {
    return createClient(
        process.env.NEXT_PUBLIC_SUPABASE_URL!,
        process.env.SUPABASE_SERVICE_ROLE_KEY!,
        { auth: { persistSession: false } }
    );
}

function normalizeBaseUrl(url: string) {
    return url.replace(/\/$/, "");
}

/**
 * Envia uma mensagem de texto simples via Uazapi.
 * Usa o mesmo padr√£o funcional do engine.ts (automa√ß√µes).
 */
async function sendTextMessage(number: string, text: string, instanceToken: string) {
    const base = process.env.UAZAPI_BASE_URL;
    if (!base || !instanceToken) {
        console.warn("[AI LOOP] sendTextMessage: UAZAPI_BASE_URL or instanceToken missing.");
        return null;
    }

    const cleanNumber = number.split("@")[0].replace(/\D/g, "");
    console.log(`[AI LOOP] Sending text to ${cleanNumber} via ${normalizeBaseUrl(base)}/send/text`);

    const res = await fetch(`${normalizeBaseUrl(base)}/send/text`, {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
            "token": instanceToken,
        },
        body: JSON.stringify({ number: cleanNumber, text }),
    });

    const raw = await res.text();
    let json: any = null;
    try { json = JSON.parse(raw); } catch { json = raw; }

    if (!res.ok) {
        console.error(`[AI LOOP] Uazapi send failed (${res.status}):`, json);
        return null;
    }

    console.log("[AI LOOP] Uazapi send OK:", typeof json === "object" ? JSON.stringify(json).substring(0, 100) : raw.substring(0, 100));
    return json;
}

/**
 * Envia Payloads Ricos (Carousel, List, Button) via Uazapi.
 * Os payloads v√™m formatados do toolHandler (send_uaz_carousel, send_uaz_list_menu, etc.)
 */
async function sendRichPayload(uazapiPayload: any, instanceToken: string) {
    const base = process.env.UAZAPI_BASE_URL;
    if (!base || !instanceToken) {
        console.warn("[AI LOOP] sendRichPayload: UAZAPI_BASE_URL or instanceToken missing.");
        return null;
    }

    // Detectar o tipo de payload e escolher o endpoint correto
    let endpoint = "/send/text"; // fallback
    if (uazapiPayload.listMessage || uazapiPayload.list) {
        endpoint = "/send/list";
    } else if (uazapiPayload.buttonsMessage || uazapiPayload.buttons) {
        endpoint = "/send/buttons";
    } else if (uazapiPayload.templateMessage || uazapiPayload.template) {
        endpoint = "/send/template";
    }

    console.log(`[AI LOOP] Dispatching Rich UI to ${normalizeBaseUrl(base)}${endpoint}`);

    const res = await fetch(`${normalizeBaseUrl(base)}${endpoint}`, {
        method: "POST",
        headers: {
            "Content-Type": "application/json",
            "token": instanceToken,
        },
        body: JSON.stringify(uazapiPayload),
    });

    const raw = await res.text();
    let json: any = null;
    try { json = JSON.parse(raw); } catch { json = raw; }

    if (!res.ok) {
        console.error(`[AI LOOP] Rich payload send failed (${res.status}):`, json);
        return null;
    }

    console.log("[AI LOOP] Rich payload sent OK.");
    return json;
}

/**
 * The main AI Tool Calling Orchestration Loop.
 * Runs independently in the background (fire-and-forget from webhook).
 */
export async function processAiMessage(params: OrchestratorParams) {
    console.log(`[AI LOOP] Started for ChatID: ${params.chatId}`);
    const supabase = getSupabaseAdmin();

    // 0. Obter o token da inst√¢ncia Uazapi para enviar mensagens
    const { data: restData } = await supabase
        .from("restaurants")
        .select("name, uaz_instance_token")
        .eq("id", params.restaurantId)
        .single();

    const instanceToken = restData?.uaz_instance_token || "";
    const restaurantName = restData?.name || "FoodSpin";

    if (!instanceToken) {
        console.error(`[AI LOOP] No uaz_instance_token found for restaurant ${params.restaurantId}. Cannot send messages.`);
        return;
    }

    // 1. Fetch History & Context
    const { data: messages } = await supabase
        .from("messages")
        .select("direction, text")
        .eq("chat_id", params.chatId)
        .order("created_at", { ascending: false })
        .limit(15);

    const { data: chatContext } = await supabase
        .from("chats")
        .select("stage_id, kanban_status, cupom_ganho, kanban_stages(name)")
        .eq("id", params.chatId)
        .single();

    if (!messages) return;

    // Convert history to Gemini format (older first)
    messages.reverse();
    const geminiHistory: Content[] = messages.map(m => ({
        role: m.direction === "in" ? "user" : "model",
        parts: [{ text: m.text || "[M√≠dia omitida]" }],
    }));

    // System Prompt embutido diretamente (evita fs.readFileSync que falha em produ√ß√£o)
    const rawPrompt = `üß† SYSTEM PROMPT: FOODSPIN OS v10.0 (Tool-Synchronized Edition)
üé≠ IDENTIDADE & TONE OF VOICE
Voc√™ √© o Gerente de Convers√£o Premium do restaurante {nome_restaurante}. Sua personalidade √© o "Dono Amigo": √°gil, prestativo, levemente informal, mas extremamente rigoroso na execu√ß√£o log√≠stica e no uso de ferramentas.

Veto Rob√≥tico: NUNCA use listas numeradas extensas, termos t√©cnicos (ex: "processando payload", "chamando API") ou blocos de texto maiores que 3 linhas.

Humaniza√ß√£o: Use interjei√ß√µes naturais ("Opa", "Putz", "Vou ver aqui") e pausas estrat√©gicas.

üõ†Ô∏è CAMADA 1: RACIOC√çNIO AG√äNTICO E INTEGRA√á√ÉO (THE BRAIN)
Para cada intera√ß√£o, voc√™ DEVE abrir um bloco <thought> para processar a l√≥gica antes de responder.

Contexto Invis√≠vel: O sistema injeta automaticamente o chat_id e o telefone do cliente nas ferramentas. NUNCA invente, pe√ßa ou tente adivinhar IDs.

Planejamento de Tool: Qual √© a pr√≥xima ferramenta exata que preciso chamar? Tenho todos os par√¢metros required preenchidos?

üíé CAMADA 2: MEM√ìRIA VIP E KANBAN
Consulte o contexto do cliente antes de saudar.

Kanban Autom√°tico: Sempre que a inten√ß√£o do cliente mudar, use move_kanban_stage com os nomes EXATOS:
- Iniciar / Sauda√ß√£o -> "Novo Lead (Roleta)"
- Se quer agendar -> "Agendamento" (ap√≥s usar schedule_proactive_followup)
- Se quer escolher lanche -> "Montando Pedido"
- Se fechou carrinho e falta pagar -> "Aguardando Pagto"
- Se pagou e foi enviado para a cozinha -> "Pedidos (Cozinha)"
- Se o cliente estiver irritado, confuso ou pedir humano -> "Atendimento Humano"
- Se o cliente desistir ou n√£o puder comprar -> "Arquivado (Perda)"

Abandono: Se o cliente parar de responder na fase de escolha, ative preventivamente schedule_proactive_followup com intent="abandoned_cart".

Lead "Roleta": Se a conversa come√ßar com "üé∞ Roleta: [Pr√™mio]", saude o cliente com entusiasmo e OBRIGATORIAMENTE ofere√ßa op√ß√µes usando send_uaz_list_menu.
    - T√≠tulo: "Parab√©ns pelo pr√™mio! üéâ"
    - Se√ß√£o: "O que deseja fazer?"
    - Op√ß√µes:
        - id: "use_coupon_now", title: "üòã Usar Agora", description: "Fazer meu pedido"
        - id: "schedule_coupon", title: "üìÖ Usar outro dia", description: "Agendar lembrete"
    - Se escolher "Usar outro dia", pergunte o dia e use schedule_proactive_followup com intent="delayed_coupon". Mova o lead para "Agendamento" usando move_kanban_stage.
    - Se escolher "Usar Agora", mova para "Montando Pedido".

üß® CAMADA 3: VITRINE E ENGENHARIA DE UPSELL
Sua fun√ß√£o √© vender e aumentar o ticket.

Busca Restrita: Ao usar search_product_catalog, voc√™ √© OBRIGADO a passar o par√¢metro category com um destes valores exatos: "principal", "bebida" ou "adicional".

Exibi√ß√£o Visual: Use send_uaz_carousel para mostrar os produtos retornados da busca.

A√ß√£o de Upsell: Sempre que o cliente pedir um "principal", busque um "adicional" ou "bebida" e fa√ßa o soft-upsell: "Cara, pra esse lanche ficar nota 10, uma [Batata/Bebida] acompanha muito bem. Mando uma pra voc√™?"

üõµ CAMADA 4: PROTOCOLO LOG√çSTICO "ZERO ERROR"
A execu√ß√£o de fechamento deve seguir esta ordem exata para n√£o quebrar o backend:

Carrinho: Use calculate_cart_total. Aten√ß√£o: Requer o customer_address (pode ser o GPS ou texto) e a lista de items. Mostre o resumo ao cliente.

Definir Pagamento: Use send_uaz_list_menu para oferecer: PIX, Dinheiro ou Cart√£o.

Endere√ßo (GPS + N√∫mero): Chame request_user_location (gera o bot√£o na Uazapi). Assim que o cliente enviar o GPS, PERGUNTE O N√öMERO DA CASA E REFER√äNCIA.

Finalizar (CR√çTICO): Chame submit_final_order OBRIGATORIAMENTE com: items, subtotal, total, address_number, gps_location e payment_method (valores exatos: "pix", "dinheiro", ou "cartao").

üö® REGRA DE OURO DO TROCO: Se payment_method for "dinheiro", voc√™ TEM QUE perguntar "Troco pra quanto?" antes e enviar o valor no campo change_for. Se n√£o enviar, a API vai rejeitar a venda.

Cobran√ßa: Se o m√©todo for "pix", acione get_pix_payment passando o amount.

‚ö†Ô∏è GUARDRAILS & PREVEN√á√ÉO DE ALUCINA√á√ÉO
Se o submit_final_order retornar erro (ex: MISSING_ADDRESS_NUMBER ou MISSING_CHANGE_FOR), n√£o entre em p√¢nico. Fale como humano: "Putz, esqueci de perguntar um detalhe importante pra mandar pra cozinha..." e pe√ßa o dado faltante.

NUNCA calcule valores de cabe√ßa. O valor real √© sempre o que volta de calculate_cart_total.

Se get_store_info mostrar a loja fechada: "Putz, {nome}, a cozinha j√° descansou por hoje! üò¥"

Se o cliente se irritar, solicitar humano ou sair do escopo de comida, pare de usar tools operacionais, mova o lead para "Atendimento Humano" e avise: "Opa, entendi. Vou chamar um dos nossos especialistas para te ajudar agora mesmo! ‚úã"`;

    const finalPromptContent = rawPrompt
        .replace(/{nome_restaurante}/g, restaurantName)
        .replace(/{kanban_status}/g, (chatContext?.kanban_stages as any)?.name || chatContext?.kanban_status || "Desconhecido")
        .replace(/{cupom_ganho}/g, chatContext?.cupom_ganho || "Nenhum");

    const conversationContext: Content[] = [...geminiHistory];

    const ctx: ToolContext = {
        restaurant_id: params.restaurantId,
        wa_chat_id: params.waChatId,
        chat_id: params.chatId,
        base_url: process.env.NEXT_PUBLIC_APP_URL || "http://localhost:3000",
    };

    let loopActive = true;
    let iteration = 0;
    const MAX_ITERATIONS = 5;

    try {
        const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!);
        const model = genAI.getGenerativeModel({
            model: "gemini-2.5-flash",
            systemInstruction: finalPromptContent,
            tools: [{ functionDeclarations: GEMINI_TOOLS }],
        });

        while (loopActive && iteration < MAX_ITERATIONS) {
            iteration++;
            console.log(`[AI LOOP] Thinking... Iteration ${iteration}`);

            const startTimeMs = Date.now();
            const response = await model.generateContent({
                contents: conversationContext
            });
            const durationMs = Date.now() - startTimeMs;

            const responseMessage = response.response;
            const usage = responseMessage.usageMetadata;

            // üìä TELEMETRY: Non-blocking log to Supabase ai_logs
            supabase.from("ai_logs").insert({
                restaurant_id: params.restaurantId,
                chat_id: params.chatId,
                wa_chat_id: params.waChatId,
                model: "gemini-2.5-flash",
                prompt_tokens: usage?.promptTokenCount || 0,
                completion_tokens: usage?.candidatesTokenCount || 0,
                total_tokens: usage?.totalTokenCount || 0,
                duration_ms: durationMs
            }).then(({ error }) => {
                if (error) console.error("[TELEMETRY] Failed to insert ai_logs:", error.message);
            });

            const functionCalls = responseMessage.functionCalls();

            if (functionCalls && functionCalls.length > 0) {
                // Gemini decided to use tools
                const functionResponses: any[] = [];

                // Add model's logic/tool requests to history
                conversationContext.push({
                    role: "model",
                    parts: functionCalls.map(fc => ({ functionCall: fc }))
                });

                for (const toolCall of functionCalls) {
                    console.log(`[AI LOOP] Executing tool: ${toolCall.name}`);
                    const args = toolCall.args;
                    const toolResultString = await executeAiTool(toolCall.name, args as any, ctx);
                    const parsedResult = JSON.parse(toolResultString);

                    // ‚îÄ‚îÄ‚îÄ INTERCEPT RICH UI (Uazapi) ‚îÄ‚îÄ‚îÄ
                    if (parsedResult.uazapi_payload) {
                        await sendRichPayload(parsedResult.uazapi_payload, instanceToken);
                        // Tell AI it was sent so it doesn't repeat itself
                        functionResponses.push({
                            functionResponse: {
                                name: toolCall.name,
                                response: { ok: true, note: "Interactive visual message sent successfully to user WhatsApp. You do not need to repeat this text." }
                            }
                        });
                    } else {
                        // Regular data response
                        functionResponses.push({
                            functionResponse: {
                                name: toolCall.name,
                                response: parsedResult
                            }
                        });
                    }
                }

                // Append the tool responses back to history
                conversationContext.push({
                    role: "function",
                    parts: functionResponses
                });

            } else {
                // Gemini produced the final natural text response
                const finalAnswer = responseMessage.text();
                if (finalAnswer) {
                    loopActive = false;
                    console.log(`[AI LOOP] Final Answer Ready: "${finalAnswer.substring(0, 80)}..."`);

                    // 1. Send to WhatsApp
                    const sendResult = await sendTextMessage(params.waChatId, finalAnswer, instanceToken);
                    const waMessageId = sendResult?.id || sendResult?.messageId || null;

                    // 2. Save to database
                    await supabase.from("messages").insert({
                        chat_id: params.chatId,
                        restaurant_id: params.restaurantId,
                        direction: "out",
                        text: finalAnswer,
                        wa_message_id: waMessageId,
                        status: "sent"
                    });

                    // 3. Update chat last_message
                    await supabase.from("chats").update({
                        last_message: finalAnswer,
                        updated_at: new Date().toISOString(),
                    }).eq("id", params.chatId);
                }
            }
        } // Fim do while

        // üõ°Ô∏è CAMADA 1: Fallback de Limite de Itera√ß√µes
        if (iteration >= MAX_ITERATIONS) {
            console.warn(`[AI LOOP] Reached loop limit (${MAX_ITERATIONS}) for ChatID: ${params.chatId}.`);

            const fallbackMessage = "Putz, deu um pequeno curto-circuito aqui no meu sistema tentando processar seu pedido! üòÖ Voc√™ poderia repetir o que deseja, por favor?";

            await sendTextMessage(params.waChatId, fallbackMessage, instanceToken);
            await supabase.from("messages").insert({
                chat_id: params.chatId,
                restaurant_id: params.restaurantId,
                direction: "out",
                text: fallbackMessage,
                status: "sent"
            });
        }

    } catch (err: any) {
        // üõ°Ô∏è CAMADA 2: Fallback de Crash Cr√≠tico
        console.error("[AI LOOP] Critical Error:", err);

        // üìä TELEMETRY: Log AI Failure
        await supabase.from("ai_logs").insert({
            restaurant_id: params.restaurantId,
            chat_id: params.chatId,
            wa_chat_id: params.waChatId,
            model: "gemini-2.5-flash",
            error_message: String(err.message || err),
            duration_ms: 0
        });

        const errorMessage = "Opa, nossa cozinha virtual est√° passando por uma instabilidade r√°pida. J√° chamei um atendente humano para assumir seu pedido e falar com voc√™, t√° bom? üë®‚Äçüç≥";

        try {
            const sendResult = await sendTextMessage(params.waChatId, errorMessage, instanceToken);
            const waMessageId = sendResult?.id || sendResult?.messageId || null;

            // Salvar a mensagem fallback no hist√≥rico do banco para aparecer no frontend
            await supabase.from("messages").insert({
                chat_id: params.chatId,
                restaurant_id: params.restaurantId,
                direction: "out",
                text: errorMessage,
                wa_message_id: waMessageId,
                status: "sent"
            });

            // Mover para Atendimento Humano
            await supabase.from("chats").update({
                kanban_status: "Atendimento Humano",
                last_message: errorMessage,
                updated_at: new Date().toISOString(),
            }).eq("id", params.chatId);
        } catch (fallbackErr) {
            console.error("[AI LOOP] Failed to send/save fallback message:", fallbackErr);
        }
    }
} // Fim da fun√ß√£o processAiMessage